##Логи

Опять не очень понятно. На данном этапе когда то тут, то там что-то пропадает и не работает, неплохо было бы собрать все логи в kibana, которые возможно собрать в рамках текущей инфраструктуры. Явно в текущей системе уже есть какое-то логирование (например, на уровне фреймворка). Логичнее было бы начать с них.

1. Shop Frontend

INFO: передача заказа на бэк (id пользователя, данные, время)

2. Shop Frontend API

INFO: добавление заказа в систему (id пользователя, данные, время)
INFO: чтение заказа (данные)

3. CRM Frontend

INFO: редактирование заказа и передача на бэк (id пользователя, данные, время)

4. CRM API

INFO: изменение статуса заказа (id пользователя, данные заказа, время)
INFO: чтение заказа (данные)

5. MES Frontend

INFO: редактирование заказа и передача на бэк (id пользователя, данные, время)

6. MES API

INFO: добавление заказа в систему (id пользователя, данные, время)
INFO: изменение статуса заказа (id пользователя, данные заказа, время)
INFO: чтение заказа (данные)

Также необходимо собирать все логи:
1. warning и error - чтобы увидеть скрытые ошибки
2. debug и trace - на первом этапе просто посмотреть, есть ли там такие артефакты от других команд, может быть там тоже будет что-то интересное. И потом бывает, что часто забывают убирать дебаг логи, которые "кишками" своими потом светят наружу.

##Мотивация

1. Повышение наблюдаемости системы (observability).
3. Customer satisfaction за счет повышение наблюдаемости.
4. Техдолг скорее всего вырастет за счет обнаружения скрытых ошибок.

В первую очередь нужно реализовать логирование и трейсинг для систем, участвующих в принятии заказа, но как я писала выше, исходя из описания системы в обработке заказа участвуют все три сервиса (+ их БД + брокер).


##Предлагаемое решение

1. Установка EKL под docker.
2. Установка сборщика логов на уровне сервиса. Тут возможны варианты, потому что под разные системы и фреймворки есть готовые библиотеки работы с kibana/elasticsearch.
3. Настройка logstash.
4. Настройка Elasticsearch. Создание индексов.
6. Настройка Kibana.

- доступ к системам логирования только из списка доверенных адресов (или VPN)
- ограничение круга лиц, имеющих доступ к данным трейсинга
- защищенные протоколы доступа (HTTPS, SSH)

Под каждый сервис свой индекс. Хранить нужно логи столько времени, чтобы была возможность в них заглянуть как по горячим следам, так и в ретроспективе. Это зависит от того, с какой периодичностью команда разработки будет туна заглядывать. На первом этапе при потенциально большом количестве логов возможно неделя-две. Размер зависит от имеющейся инфраструктуры.

#Анализ логов

1. Если мы используем Kibana, то можно создать готовые фильтры для подготовки интересующей нас информации. Это будет упрощать анализ.
2. Аллертинг при получении ответа от страницы с кодом ошибки (5хх, 4хх).
3. Аллертинг при превышении определённого количества запросов в секунду (DoS, DDoS)
4. Аллертинг на конкретный тип exception, например, если он для нас критичен.
