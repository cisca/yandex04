##Мотивация

1. В системе пропадают заказы. Мониторинг позволит выявить узкие места системы, а так же (возможно, при соотестветствующей настройке) по логам восстановить потерянные данные.
2. При дальнейшем масштабировании мониторинг и логирование также позволят выявлять узкие места системы и заранее предпринимать меры по их ликвидации до того, как проблемы начнут носить критичный характер.
3. Поможет команде разработки увидить программые ошибки прода и сфокусироваться на качестве работы продукта. Кроме того, это позволит отлавливать ошибки в dev среде и эффективнее их исправлять.

##Выбор подхода к мониторингу

- Shop Frontend - RED
    + Number of requests (RPS) for internet shop frontend - чтобы увидеть профиль нагрузки на сервис. *Метки: url*
    + Number of requests (RPS) per user for internet shop frontend - чтобы рассчитать, как будет увеличиваться нагрузка на сервис при планировании увеличения количества пользователей. *Метки: url, session id*
    + CPU % for shop frontend - можно посмотреть нет ли нагрузки на процессор, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Memory Utilisation for shop frontend - можно посмотреть нет ли нагрузки на память, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой

- Shop Backend - 4 golden signals
    + Number of requests (RPS) for internet shop API - чтобы увидеть профиль нагрузки на сервис. *Метки: url*
    + Number of requests (RPS) per user for internet shop API - чтобы рассчитать, как будет увеличиваться нагрузка на сервис при планировании увеличения количества пользователей. *Метки: url, session id*
    + CPU % for shop API - можно посмотреть нет ли нагрузки на процессор, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Memory Utilisation for shop API - можно посмотреть нет ли нагрузки на память, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Response time (latency) for shop API - можно посмотреть, справляется ли сервис с загрузкой и сколько времени нужно серверу, чтобы отправить ответ и не отваливается ли он по таймауту
    + Number of simultanious sessions for shop API - можно посмотреть, закрываются ли сессии, например. если они не завершаются, то это может форкать процессы сервера и давать нагрузку на память и процессор
    + Kb tranferred (received) for shop API - можно посмотреть, есть ли "жирные" данные, которые долго передаются и замедляют работу сервера. *Метки: url запроса, id пользователя/сессии*
    + Kb provided (sent) for shop API - можно посмотреть, есть ли "жирные" ответы, которые долго передаются и замедляют работу сервера. *Метки: id пользователя/сессии*

- Shop DB - RED
    + Memory Utilisation for shop db instance - можно посмотреть нет ли нагрузки на память, в случае если БД не справляется с нагрузкой.
    + Number of connections for shop db instance - можно посмотреть, нет ли превышения лимита подключений к БД
    + Size of shop db instance - наблюдаем не превышен ли лимит по размеру

- CRM Frontend - RED
    + Number of requests (RPS) for CRM frontend - чтобы увидеть профиль нагрузки на сервис. *Метки: url*
    + Number of requests (RPS) per user for CRM frontend - чтобы рассчитать, как будет увеличиваться нагрузка на сервис при планировании увеличения количества пользователей. *Метки: url, session id*
    + CPU % for CRM frontend - можно посмотреть нет ли нагрузки на процессор, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Memory Utilisation for CRM frontend - можно посмотреть нет ли нагрузки на память, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой

- CRM Backend - 4 golden signals
    + Number of requests (RPS) for CRM API - чтобы увидеть профиль нагрузки на сервис. *Метки: url*
    + Number of requests (RPS) per user for CRM API - чтобы рассчитать, как будет увеличиваться нагрузка на сервис при планировании увеличения количества пользователей. *Метки: url, session id*
    + CPU % for CRM API - можно посмотреть нет ли нагрузки на процессор, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Memory Utilisation for CRM API - можно посмотреть нет ли нагрузки на память, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Response time (latency) for CRM API - можно посмотреть, справляется ли сервис с загрузкой и сколько времени нужно серверу, чтобы отправить ответ и не отваливается ли он по таймауту
    + Number of simultanious sessions for CRM API - можно посмотреть, закрываются ли сессии, например. если они не завершаются, то это может форкать процессы сервера и давать нагрузку на память и процессор
    + Kb tranferred (received) for CRM API - можно посмотреть, есть ли "жирные" данные, которые долго передаются и замедляют работу сервера. *Метки: url запроса, id пользователя/сессии*
    + Kb provided (sent) for CRM API - можно посмотреть, есть ли "жирные" ответы, которые долго передаются и замедляют работу сервера. *Метки: id пользователя/сессии*

- Message Queue - RED
    + Number of dead-letter-exchange letters in RabbitMQ - смотреть, что происходит с очередью в брокере. *Метки: отправитель (сервис), содержание (данные)*
    + Number of message in flight in RabbitMQ - сопоставив это значение с другими, можно понять, если допустим где-то потерялись данные, связано ли это с очередью сообщений

- MES Frontend - RED
    + Number of requests (RPS) for MES frontend - чтобы увидеть профиль нагрузки на сервис. *Метки: url*
    + Number of requests (RPS) per user for MES frontend - чтобы рассчитать, как будет увеличиваться нагрузка на сервис при планировании увеличения количества пользователей. *Метки: url, session id*
    + CPU % for MES frontend - можно посмотреть нет ли нагрузки на процессор, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Memory Utilisation for MES frontend - можно посмотреть нет ли нагрузки на память, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой

- MES Backend - 4 golden signals
    + Number of requests (RPS) for MES API - чтобы увидеть профиль нагрузки на сервис. *Метки: url*
    + Number of requests (RPS) per user for MES API - чтобы рассчитать, как будет увеличиваться нагрузка на сервис при планировании увеличения количества пользователей. *Метки: url, session id*
    + CPU % for MES API - можно посмотреть нет ли нагрузки на процессор, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Memory Utilisation for MES API - можно посмотреть нет ли нагрузки на память, например, из-за форков процесса вэб-сервера, который не справляется с нагрузкой
    + Response time (latency) for MES API - можно посмотреть, справляется ли сервис с загрузкой и сколько времени нужно серверу, чтобы отправить ответ и не отваливается ли он по таймауту
    + Number of simultanious sessions for MES API - можно посмотреть, закрываются ли сессии, например. если они не завершаются, то это может форкать процессы сервера и давать нагрузку на память и процессор
    + Kb tranferred (received) for MES API - можно посмотреть, есть ли "жирные" данные, которые долго передаются и замедляют работу сервера. *Метки: url запроса, id пользователя/сессии*
    + Kb provided (sent) for MES API - можно посмотреть, есть ли "жирные" ответы, которые долго передаются и замедляют работу сервера. *Метки: id пользователя/сессии*

- MES DB - RED
    + Memory Utilisation for MES db instance - можно посмотреть нет ли нагрузки на память, в случае если БД не справляется с нагрузкой
    + Number of connections for MES db instance - можно посмотреть, нет ли превышения лимита подключений к БД
    + Size of MES db instance - наблюдаем не превышен ли лимит по размеру

- File Storage - USE
    + Size of S3 storage - наблюдаем не превышен ли лимит по хранилищу

##План действий
1. Устанавливаем Prometheus в docker, предварительно настроив конфигурацию.
2. Запускам и проверяем, что сервис работает и запускается на нужном нам порту.
3. Устанавливаем Grafana в docker, предварительно настроив конфигурацию.
4. Запускам и проверяем, что сервис работает и запускается на нужном нам порту.
5. Добавляем источники данных.
6. Устанавливаем ELK в docker, предварительно настроив конфигурацию.
7. Настраиваем Elasticsearch, Logstash, Kibana. Устанавливаем и настраиваем Filebeat.
8. Запускам и проверяем, что сервис работает и запускается на нужном нам порту.
9. Настраиваем Kibanа, добавляем индексы.

